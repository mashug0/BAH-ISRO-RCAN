# ğŸ›°ï¸ RADIAN: Noise-Aware Dual Image Super-Resolution for Satellite Imagery  
**Bharatiya Antariksh Hackathon 2025 â€“ ISRO (Problem Statement 12)**  
**Team:** Mangal Mandli Â· *IIT Guwahati*  
**Members:** Saksham Gupta Â· Yashvi Mehta Â· Govind Akash Sanghani Â· Nalin Goel  

---

## ğŸš€ Overview

**RADIAN (Robust Alignment and Dual-image Attention Network)** is a deep learning framework for **dual-image super-resolution (SR)** of optical satellite imagery.  
The model leverages **two adjacent low-resolution (LR)** frames to reconstruct a **high-resolution (HR)** image with improved spatial fidelity and noise robustness.

This project was developed as part of the **Bharatiya Antariksh Hackathon 2025 (ISRO)** under *Problem Statement 12 â€“ Dual Image Super-Resolution and Blind Evaluation.*

---

## ğŸ§© Core Architecture

RADIAN integrates two complementary modules for enhanced reconstruction:

### 1ï¸âƒ£ Noise-Aware TDAN (Temporal Deformable Alignment Network)
- Aligns two degraded LR frames using **deformable convolutions**.  
- A **Noise Estimation Module** predicts pixel-wise noise maps that guide alignment.  
- The **Alignment Refinement Unit** ensures smooth spatial correspondence even under orbital jitter.

### 2ï¸âƒ£ Lite RCAN (Residual Channel Attention Network)
- A lightweight version of RCAN optimized for memory and inference efficiency.  
- Employs **Channel Attention Blocks** and **Global Residual Fusion** to enhance textures and fine details.  
- Works jointly with TDAN to reconstruct HR images that balance fidelity and perceptual sharpness.

---

## âš™ï¸ Training & Evaluation Pipeline

1. **Synthetic Dataset Creation (`Dataset/`)**  
   - High-res images are degraded using a **physics-based model** (Gaussian blur, MTF noise, sub-pixel shifts, and random downsampling).  
   - The degradation process follows *Zhang et al., ICCV 2021* for realistic satellite conditions.

2. **Dual-Input SR Model (`Model/`)**  
   - Two LR frames â†’ deformable alignment (Noise-Aware TDAN) â†’ feature fusion â†’ Lite RCAN reconstruction.  
   - **Loss Framework:**
     - Alignment Loss â€“ temporal consistency  
     - Reconstruction Loss â€“ pixel fidelity  
     - Noise Modeling Loss â€“ aligns with estimated noise map  
     - Edge Preservation Loss â€“ structural sharpness  
     - Perceptual Loss â€“ enhances visual realism (LPIPS)

3. **Blind Image Quality Assessment (`BIQA/`)**  
   - A no-reference IQA model (BIECON + Gradient Sharpness features).  
   - Predicts perceptual quality without ground-truth HR references.  
   - Trained on synthetically degraded data for robustness.

---

## ğŸ§  Folder Structure
<pre>
BAH-ISRO-RCAN/
â”œâ”€â”€ BIQA/                          # Blind Image Quality Assessment (No-reference evaluator)
â”‚   â”œâ”€â”€ Degrador.py
â”‚   â”œâ”€â”€ ExtractMos.py
â”‚   â”œâ”€â”€ ExtractSSIM.py
â”‚   â”œâ”€â”€ Train.py / Test.py
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ BIECON.py
â”‚   â”‚   â”œâ”€â”€ BlindEvalModel.py
â”‚   â”‚   â”œâ”€â”€ GradientSharpness.py
â”‚   â”‚   â””â”€â”€ TrainModel.py
â”‚   â””â”€â”€ mos.csv
â”‚
â”œâ”€â”€ Dataset/                       # Dataset creation and degradation scripts
â”‚   â”œâ”€â”€ CreateDataset.py
â”‚   â”œâ”€â”€ Degrador.py
â”‚   â””â”€â”€ Extractor.py
â”‚
â”œâ”€â”€ Model/                         # Core Dual-Image Super-Resolution Model
â”‚   â”œâ”€â”€ NoiseAwareTDAN.py
â”‚   â”œâ”€â”€ liteRCAN.py
â”‚   â”œâ”€â”€ NoiseEstimator.py
â”‚   â”œâ”€â”€ MultiComponentLoss.py
â”‚   â”œâ”€â”€ DeformConv2d.py
â”‚   â””â”€â”€ Allignment.py
â”‚
â”œâ”€â”€ DatasetLoader.py               # Dataset loader utilities
â”œâ”€â”€ MODEL_NOTEBOOK.ipynb           # ğŸ”¹ Main notebook to run Super-Resolution
â””â”€â”€ PS12_Mangal Mandli .pptx       # Presentation slides (Hackathon submission)
</pre>


BIQA/model is not relevant to the Model Used. it will be updated soon.
best_model.pth, some checkpoint_epoch_num.pth fies are added to branch test-model


---

## ğŸ§® How to Run

### ğŸ”¹ For Super-Resolution:
Simply open and run the following notebook:

```bash
MODEL_NOTEBOOK.ipynb
```
This notebook covers:
Data loading

Model initialization (Noise-Aware TDAN + Lite RCAN)

Training & inference

Visualization of LR vs SR vs Ground Truth

No command-line execution is required â€” the full workflow runs inside the notebook.
Qualitative Results:

Sharper edges in roads, vegetation, and water boundaries.

Fine micro-textures recovered under noise and blur.

Strong alignment and perceptual consistency compared to single-frame SR baselines.

ğŸ§° Tools & Frameworks

Deep Learning: PyTorch

Image Processing: OpenCV, PIL

Visualization: Matplotlib, tqdm

Evaluation: PSNR, SSIM, LPIPS, BRISQUE, NIQE

Optimization: Adam, EMA updates

Inference Acceleration: TensorRT supported


